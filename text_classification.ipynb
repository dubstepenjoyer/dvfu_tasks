{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64acc7fb-59de-4ebc-b82f-afb53cc852d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3379e5ef-2708-48c0-a8ed-95eda57a8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588f5af-a33c-4638-90d8-5cb912535790",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c468a19b-1395-4afc-b0c5-a799160ea671",
   "metadata": {},
   "source": [
    "Load and prepare your dataset. Dataset should have at least 10k samples in it. Each dataset cannot be used by more than two students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27724773-5172-4a0f-87ab-6878341a7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('text_emotion_data.parquet').drop(\n",
    "    [\n",
    "        'ru_text',\n",
    "        'id',\n",
    "        'author',\n",
    "        'subreddit',\n",
    "        'link_id',\n",
    "        'parent_id',\n",
    "        'created_utc',\n",
    "        'rater_id',\n",
    "        'example_very_unclear',\n",
    "        ],\n",
    "        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175855c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = {\n",
    "    0: 'admiration',\n",
    "    1: 'amusement',\n",
    "    2: 'anger',\n",
    "    3: 'annoyance',\n",
    "    4: 'approval',\n",
    "    5: 'caring',\n",
    "    6: 'confusion',\n",
    "    7: 'curiosity',\n",
    "    8: 'desire',\n",
    "    9: 'disappointment',\n",
    "    10: 'disapproval',\n",
    "    11: 'disgust',\n",
    "    12: 'embarrassment',\n",
    "    13: 'excitement',\n",
    "    14: 'fear',\n",
    "    15: 'gratitude',\n",
    "    16: 'grief',\n",
    "    17: 'joy',\n",
    "    18: 'love',\n",
    "    19: 'nervousness',\n",
    "    20: 'optimism',\n",
    "    21: 'pride',\n",
    "    22: 'realization',\n",
    "    23: 'relief',\n",
    "    24: 'remorse',\n",
    "    25: 'sadness',\n",
    "    26: 'surprise',\n",
    "    27: 'neutral',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926a0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_emotions = {\n",
    "    0: 'восхищение',\n",
    "    1: 'веселье',\n",
    "    2: 'злость',\n",
    "    3: 'раздражение',\n",
    "    4: 'одобрение',\n",
    "    5: 'забота',\n",
    "    6: 'непонимание',\n",
    "    7: 'любопытство',\n",
    "    8: 'желание',\n",
    "    9: 'разочарование',\n",
    "    10: 'неодобрение',\n",
    "    11: 'отвращение',\n",
    "    12: 'смущение',\n",
    "    13: 'возбуждение',\n",
    "    14: 'страх',\n",
    "    15: 'признательность',\n",
    "    16: 'горе',\n",
    "    17: 'радость',\n",
    "    18: 'любовь',\n",
    "    19: 'нервозность',\n",
    "    20: 'оптимизм',\n",
    "    21: 'гордость',\n",
    "    22: 'осознание',\n",
    "    23: 'облегчение',\n",
    "    24: 'раскаяние',\n",
    "    25: 'грусть',\n",
    "    26: 'удивление',\n",
    "    27: 'нейтральность',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "219e25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_emotion = {id_to_label[i]: ru_emotions[i] for i in range(len(id_to_label))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89490157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admiration': 'восхищение',\n",
       " 'amusement': 'веселье',\n",
       " 'anger': 'злость',\n",
       " 'annoyance': 'раздражение',\n",
       " 'approval': 'одобрение',\n",
       " 'caring': 'забота',\n",
       " 'confusion': 'непонимание',\n",
       " 'curiosity': 'любопытство',\n",
       " 'desire': 'желание',\n",
       " 'disappointment': 'разочарование',\n",
       " 'disapproval': 'неодобрение',\n",
       " 'disgust': 'отвращение',\n",
       " 'embarrassment': 'смущение',\n",
       " 'excitement': 'возбуждение',\n",
       " 'fear': 'страх',\n",
       " 'gratitude': 'признательность',\n",
       " 'grief': 'горе',\n",
       " 'joy': 'радость',\n",
       " 'love': 'любовь',\n",
       " 'nervousness': 'нервозность',\n",
       " 'optimism': 'оптимизм',\n",
       " 'pride': 'гордость',\n",
       " 'realization': 'осознание',\n",
       " 'relief': 'облегчение',\n",
       " 'remorse': 'раскаяние',\n",
       " 'sadness': 'грусть',\n",
       " 'surprise': 'удивление',\n",
       " 'neutral': 'нейтральность'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714bddcc-c56d-4e61-9147-054f5d7f8e7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a2f49-08a6-479a-8db7-a52d4db40d56",
   "metadata": {},
   "source": [
    "Load pretrained model from Hugging Face (or some other model repository if it's more convenient). Model should be trained on Feature Extraction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d111bc81-dfb4-47fb-b3d8-42388b84a8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBartModel.\n",
      "\n",
      "All the weights of TFBartModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "backbone = transformers.TFAutoModel.from_pretrained('./bart-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b81337a-c06e-4b33-9dff-61ff0c6858c9",
   "metadata": {},
   "source": [
    "Load tokenizer to be used with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c7e98fb-a356-463d-a856-9b011efdcca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045f3c1-faf9-41fc-af88-a4f49c97ac13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1025d0d6-3b43-440a-8791-27b3e208e415",
   "metadata": {},
   "source": [
    "Since we will not be training the backbone, extract features from your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb0bf5-6e28-49fa-a0c3-e5b3fd51e7f7",
   "metadata": {},
   "source": [
    "Tokenize all your sequences. Truncate/pad the squences for convenience. If the sequences are too large to be stored in memory, lazily save them on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3fcfd80-cfba-45e2-8767-05bd5169b814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad3386074f143f3a62772d70299979a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenize_seq = []\n",
    "\n",
    "for text in tqdm.tqdm(data['text']):\n",
    "    tokenize_seq.append(tokenizer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b4b64-ee2e-4a2a-8d81-161f8bf1aae4",
   "metadata": {},
   "source": [
    "Run the backbone on the sequences and save the extracted features. The extracted features should be a vector containing information about the whole text. If the features are too large to be stored in memory, lazily save them on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c81f850-a0ca-4951-8677-0597aedb21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences([i['input_ids'] for i in tokenize_seq], maxlen=128, truncating='post', padding='post', value=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b325f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[data.columns.difference(['text'])].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "276e08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices(X).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd7f7a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9752eaa7e349cc9400cac314fa54fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = []\n",
    "\n",
    "for data in tqdm.tqdm(text_dataset):\n",
    "    features.extend(tf.math.reduce_mean(backbone(data).last_hidden_state, axis=1))\n",
    "\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83e7088d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.9268482 , -1.8083783 ,  1.1634356 , ..., -0.25005838,\n",
       "          1.684664  ,  0.59326035],\n",
       "        [ 1.2231605 , -1.1030577 , -0.28428376, ...,  1.1343532 ,\n",
       "          1.3022391 ,  0.54750144],\n",
       "        [ 1.9432738 , -1.8364208 ,  0.81785935, ...,  0.1901779 ,\n",
       "          0.8832531 ,  0.98668087],\n",
       "        ...,\n",
       "        [ 2.0871496 , -1.9621882 ,  0.7568142 , ..., -0.07704715,\n",
       "          1.2768964 ,  0.62696475],\n",
       "        [ 1.5172942 , -1.0947775 , -0.6264874 , ...,  0.84136087,\n",
       "          1.7282301 ,  1.0637035 ],\n",
       "        [ 1.5030369 , -0.8643758 , -0.8128365 , ...,  1.1897686 ,\n",
       "          1.5710945 ,  0.9328568 ]], dtype=float32),\n",
       " (211225, 768))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543fcff-46b0-4c05-b297-c3102f998205",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prepare train/test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c985c7d-9123-477e-9988-15ff5a7b26eb",
   "metadata": {},
   "source": [
    "Split your data (extracted features and labels) into train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5460c05a-f5e7-4935-a6ff-074ca21fa01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4825e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "X_test_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "y_train_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "y_test_dataset = tf.data.Dataset.from_tensor_slices(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a65639-50d0-4f89-8bfe-33b7a483e406",
   "metadata": {},
   "source": [
    "Prepare `tf.data.Dataset` or some other way for the data to be used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07849c2e-c7d1-4620-9590-962fa554ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.zip((X_train_dataset, y_train_dataset)).batch(256)\n",
    "test_dataset = tf.data.Dataset.zip((X_test_dataset, y_test_dataset)).batch(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f74abd-ce1a-4a68-be6c-89b1abd0caa5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78885e31-c91e-4ee5-acbf-00a107069da9",
   "metadata": {},
   "source": [
    "Build a simple model. The model should accept an extracted feature vector and return a vector of class logits (or probabilities). Model should only have a couple (or even 1) layer with weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e808e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU not enable\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print('GPU enable')\n",
    "    except:\n",
    "        print('GPU not enable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4522f1a0-1555-4dcd-9117-3e975d6f781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(768, name='input', dtype=tf.int32)\n",
    "x = tf.keras.layers.Dense(512, name='Dense1', activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(len(translate_emotion), name='prediction')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x, name='MyModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cacc4e-9876-40ff-8cd0-f1a4bfbc5c1a",
   "metadata": {},
   "source": [
    "Compile the model. Choose loss and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad74527b-c793-40da-af8e-66172db170f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08006d-be0a-4828-aca9-a9f37218b8de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a30787b-7ac4-4dd3-9ea5-62c94e9aa628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619/619 [==============================] - 3s 5ms/step - loss: 269.1809 - accuracy: 0.1014 - val_loss: 357.6000 - val_accuracy: 0.0139\n",
      "Epoch 2/5\n",
      "619/619 [==============================] - 3s 5ms/step - loss: 315.1047 - accuracy: 0.1004 - val_loss: 311.7814 - val_accuracy: 0.0042\n",
      "Epoch 3/5\n",
      "619/619 [==============================] - 3s 5ms/step - loss: 384.2775 - accuracy: 0.0990 - val_loss: 290.2991 - val_accuracy: 0.0449\n",
      "Epoch 4/5\n",
      "619/619 [==============================] - 3s 5ms/step - loss: 426.5614 - accuracy: 0.1007 - val_loss: 373.0260 - val_accuracy: 0.0838\n",
      "Epoch 5/5\n",
      "619/619 [==============================] - 3s 5ms/step - loss: 469.8770 - accuracy: 0.0997 - val_loss: 420.9234 - val_accuracy: 0.2619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x266cd32e2c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=test_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3980f062-220a-4a11-b9f5-3b0e41804533",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6008a2-9882-44f2-946c-23827aa5fa49",
   "metadata": {},
   "source": [
    "Evalute the model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b4ddf9e-5710-4c7f-ac58-4d94742c0d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 2s 4ms/step - loss: 420.9265 - accuracy: 0.2619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[420.9265441894531, 0.26189708709716797]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96f4ae8-6b6c-4c4d-94dc-be8062b7e982",
   "metadata": {},
   "source": [
    "Plot confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b092eae2-5f9a-42cc-ba04-ae9b9f67df7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1651/1651 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix type of y not allowed, got types {'multilabel-indicator', 'binary'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dmitry\\Desktop\\Jupiter\\dvfu_tasks\\text_classification.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dmitry/Desktop/Jupiter/dvfu_tasks/text_classification.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ConfusionMatrixDisplay\u001b[39m.\u001b[39;49mfrom_predictions(y_test, model\u001b[39m.\u001b[39;49mpredict(X_test)\u001b[39m.\u001b[39;49margmax(axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\dmitry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:459\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.from_predictions\u001b[1;34m(cls, y_true, y_pred, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m display_labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m         display_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n\u001b[0;32m    460\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m         display_labels \u001b[39m=\u001b[39m labels\n",
      "File \u001b[1;32mc:\\Users\\dmitry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:86\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     83\u001b[0m     ys_types \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     85\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ys_types) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 86\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMix type of y not allowed, got types \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m ys_types)\n\u001b[0;32m     88\u001b[0m label_type \u001b[39m=\u001b[39m ys_types\u001b[39m.\u001b[39mpop()\n\u001b[0;32m     90\u001b[0m \u001b[39m# Check consistency for the indicator format\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Mix type of y not allowed, got types {'multilabel-indicator', 'binary'}"
     ]
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, model.predict(X_test).argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997d559-de7f-4e67-96f1-85df047dcbb7",
   "metadata": {},
   "source": [
    "Write a function to classify a piece of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a748d8-b5a2-4f90-a3d8-ee36d69d34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text: str) -> tuple[int | str, np.ndarray]:\n",
    "    '''Classifes the given `text` using the trained model.\n",
    "\n",
    "    Arguments:\n",
    "        text: text to be classified\n",
    "\n",
    "    Return:\n",
    "        The assigned label and probabilites of all labels'''\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2043ad-8f1b-4c17-8f11-23487f66db5f",
   "metadata": {},
   "source": [
    "Evaluate the model on text not present in training and test data (come up with the text yourself). Try to get an input for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c5386-cc1b-4040-a5b7-cb8d26965fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd49c775-eded-4a49-b7f4-9903185a7b9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c617b-7110-4761-9806-975d5f84bf41",
   "metadata": {},
   "source": [
    "Write a function that computes word impact on text label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a46658-8770-4d53-94ec-b7651dbde221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_impact(text: str) -> list[tuple[str, np.ndarray]]:\n",
    "    '''Determines word impact on text label.\n",
    "\n",
    "    Arguments:\n",
    "        text: Sample text to be used for computation.\n",
    "\n",
    "    Returns:\n",
    "        A list of pairs: the word and vector of probability changes for each class'''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6dbd69-ea3c-41df-943c-16a379384b16",
   "metadata": {},
   "source": [
    "Try to find out words that make text have a specific label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bbbaf8-68f6-4aa1-af37-f29b1edae464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
