{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edb1dbe-20ad-49d3-aabf-27a0438da7e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1d6d12-e770-47ce-a9eb-fb93b7a2b755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmitry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:246: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.bool8: (False, True),\n",
      "c:\\Users\\dmitry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:326: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.bool8: (False, True),\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gymnasium.utils.save_video import save_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011e03a4-a0ea-4ce2-9f00-e09b9b4c2e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU enable\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print('GPU enable')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e580a6f-a987-40ec-9864-2e296bdd9ba6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120abf50-431d-4c8c-bc71-e760aa7c08b4",
   "metadata": {},
   "source": [
    "Create the environment. You can use any ATARI environment from [here](https://gymnasium.farama.org/environments/atari/), but prefer to use environments with discrete action space with fewer actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9241b5-510e-4a18-bcde-8bf3c5ac2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('ALE/AirRaid-v5', render_mode='rgb_array')\n",
    "eval_env = gym.make('ALE/AirRaid-v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d50e1d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmitry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f41fb249d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "plt.imshow(env.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828a718-db96-42f6-890f-265163fdedb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Replay Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a88e3-0524-4d4f-9bd5-eb035d80fece",
   "metadata": {},
   "source": [
    "Create a replay buffer to hold game history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a761715-1ef6-4ffd-b710-1758f292888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "\n",
    "    def __init__(self, max_size: int, observation_space: gym.spaces.Space, action_space: gym.spaces.Space, seed: int | None = None):\n",
    "        \"\"\"Stores the replay history with a maximum of `max_size` entries, removing old entries as needed.\n",
    "\n",
    "        Parameters:\n",
    "            max_size: maximal number of entries to keep\n",
    "            observation_space: specification of the observation space\n",
    "            action_space: specification of the action space\n",
    "            seed: seed to initialize the internal random number generator for reproducibility\"\"\"\n",
    "        self.max_size = max_size\n",
    "        self.done = np.zeros(max_size)\n",
    "        self.step = 0\n",
    "        self.rng = np.random.default_rng(seed=seed)\n",
    "        self.len = 0\n",
    "\n",
    "        self.current_state = np.zeros((max_size, *observation_space.shape))\n",
    "        self.action = np.zeros((max_size, *action_space.shape), dtype=int)\n",
    "        self.reward = np.zeros(max_size)\n",
    "        self.next_state = np.zeros((max_size, *observation_space.shape))\n",
    "        \n",
    "    def add(self, current_observation: np.ndarray, action: int, reward: float, next_observation: np.ndarray, done: bool) -> None:\n",
    "        \"\"\"Add a new entry to the buffer.\n",
    "\n",
    "        Parameters:\n",
    "            current_observation: environment state observed at the current step\n",
    "            action: action taken by the model\n",
    "            reward: reward received after taking the action\n",
    "            next_observation: environment state obversed after taking the action\n",
    "            done: whether the episode has ended or not\"\"\"\n",
    "        self.current_state[self.step] = current_observation\n",
    "        self.action[self.step] = action\n",
    "        self.reward[self.step] = reward\n",
    "        self.next_state[self.step] = next_observation\n",
    "        self.done[self.step] = done\n",
    "        self.step = (self.step + 1) % self.max_size\n",
    "        self.len = min(self.len + 1, self.max_size)\n",
    "        \n",
    "    def sample(self, n_samples: int, replace: bool = True) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Randomly samples `n_samples` from the buffer.\n",
    "\n",
    "        Parameters:\n",
    "            n_samples: number of samples to select\n",
    "            replace: sample with or without replacement\n",
    "\n",
    "        Returns:\n",
    "            current observations, actions, rewards, next observations, done\"\"\"\n",
    "        indicies = self.rng.choice(self.len, size=n_samples, replace=replace)\n",
    "        return (\n",
    "            self.current_state[indicies], \n",
    "            self.action[indicies], \n",
    "            self.reward[indicies], \n",
    "            self.next_state[indicies], \n",
    "            self.done[indicies]\n",
    "        )\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clears the buffer\"\"\"\n",
    "        self.step = self.len = 0\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Gets a sample at `index`\n",
    "\n",
    "        Parameters:\n",
    "            index: index of the sample to get\n",
    "\n",
    "        Returns:\n",
    "            current observation, action, reward, next observation, done\"\"\"\n",
    "        return (\n",
    "            self.current_state[index], \n",
    "            self.action[index], \n",
    "            self.reward[index], \n",
    "            self.next_state[index], \n",
    "            self.done[index]\n",
    "        )\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the number of entries in the buffer\"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669485c5-5787-4ffa-82f2-58f6f0acc151",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc62c869-195b-4323-bdb4-dd53879455c9",
   "metadata": {},
   "source": [
    "Implement your model. Most if not all ATARI environments have an image observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bd7fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(prefix: str | None = None, suffix: str | None = None, separator: str = '/') -> str | None:\n",
    "    return prefix and prefix + separator + suffix or suffix or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a572a086-e9ce-4194-8809-54a8e05477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "    input_features: tuple | int, \n",
    "    features: int,\n",
    "    out_features: tuple | int,\n",
    "    blocks: int, \n",
    "    dropout: float = 0.2,\n",
    "    multiply_freq: int = 1,\n",
    "    name: str | None = None\n",
    ") -> tf.keras.Model:\n",
    "    inputs = x = tf.keras.layers.Input(input_features, name=get_name(name, 'input'))\n",
    "\n",
    "    for i in range(blocks):\n",
    "        x = tf.keras.layers.Conv2D(features, 3, padding='same', name=get_name(name, f'conv2d_1st_{i}'))(x)\n",
    "        x = tf.keras.layers.Conv2D(features, 3, padding='same', name=get_name(name, f'conv2d_2st_{i}'))(x)\n",
    "        x = tf.keras.layers.PReLU(name=get_name(name, f'PReLU_1st_{i}'))(x)\n",
    "        x = tf.keras.layers.MaxPool2D((2, 2), name=get_name(name, f'maxPOOL2d_{i}'))(x)\n",
    "        \n",
    "        if dropout > 0:\n",
    "            x = tf.keras.layers.Dropout(dropout, name=get_name(name, f'dropout_{i}'))(x)\n",
    "\n",
    "        if multiply_freq > 0 and (i + 1) % multiply_freq == 0:\n",
    "            features *= 2\n",
    "\n",
    "    x = tf.keras.layers.MaxPool2D((2, 2), name=get_name(name, f'maxPOOL2d_final'))(x)\n",
    "    x = tf.keras.layers.Flatten(name=get_name(name, 'flattenidze'))(x)\n",
    "    x = tf.keras.layers.Dense(out_features, name=get_name(name, 'prediction'))(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f6a53-ffa2-44ee-985b-a8bd921592fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e44c932-378b-4bff-b11d-20b4b879de9a",
   "metadata": {},
   "source": [
    "Implement the sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de070f1-c6b7-4a4a-81ae-e471f159e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    \n",
    "    def __init__(self, epsilon: float, seed: int | None = None):\n",
    "        \"\"\"Selects a random action with probability `epsilon` otherwise selects the most probably action given by the model.\n",
    "\n",
    "        Parameters:\n",
    "            epsilon: the probability to select a random action\n",
    "            seed: seed to initialize the internal random number generator for reproducibility\"\"\"\n",
    "        self.rng = np.random.default_rng(seed=seed)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def __call__(self, probabilities: np.ndarray) -> int:\n",
    "        \"\"\"Select an action given the `probabilities\n",
    "\n",
    "        Parameters:\n",
    "            probabilities: probabilities for each action\n",
    "\n",
    "        Returns:\n",
    "            index of the selected action\"\"\"\n",
    "\n",
    "        if self.rng.random() < self.epsilon:\n",
    "            return self.rng.integers(probabilities.shape[-1])\n",
    "        return np.argmax(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2cc1a3-3e45-4aac-8936-d5d45cc256f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Play the game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa11b5-0ca1-4bfb-91a0-33a4f8922ae9",
   "metadata": {},
   "source": [
    "Implement interacting with the environment and storing entries to the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b333e6b3-853a-4cb7-aea3-8c501d0247d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(model: tf.keras.Model, buffer: ReplayBuffer | None, env: gym.Env, max_steps: int, sampler: Sampler, observation: np.ndarray | None = None) -> np.ndarray:\n",
    "    \"\"\"Play game and record\n",
    "\n",
    "    Parameters:\n",
    "        model: the model to get actions with\n",
    "        buffer: replay buffer to store the entries to\n",
    "        env: environment to play\n",
    "        max_steps: maximal number of steps to perform\n",
    "        sampler: sampler to use to sample actions\n",
    "        observation: the observation to resume from\n",
    "\n",
    "    Returns:\n",
    "        the last observation\"\"\"\n",
    "    if observation is None:\n",
    "        observation, _ = env.reset()\n",
    "\n",
    "    buffer = buffer if buffer is not None else ReplayBuffer(1)\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        a = sampler(model(observation[None], training=False).numpy()[0])\n",
    "        \n",
    "        new_observation, score, done, terminated, _ = env.step(a)\n",
    "        \n",
    "        buffer.add(observation, a, score, new_observation, done)\n",
    "\n",
    "        if done or terminated:\n",
    "            observation, _ = env.reset()\n",
    "            continue\n",
    "            \n",
    "        observation = new_observation\n",
    "\n",
    "    return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ad3a7-0487-49d3-9ca4-6b6bbc3fa450",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcbeef8-70fb-44ae-92e9-0baea77e8f0e",
   "metadata": {},
   "source": [
    "Implement double q learning loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9775cbc-77a8-4b02-ab0a-3fbb22b3e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qq_loss(\n",
    "    current_observation: tf.Tensor, \n",
    "    action: tf.Tensor, \n",
    "    reward: tf.Tensor, \n",
    "    next_observation: tf.Tensor, \n",
    "    done: tf.Tensor,\n",
    "    model: tf.keras.Model,\n",
    "    target_model: tf.keras.Model,\n",
    "    gamma: float\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Computes double q learning loss.\n",
    "\n",
    "    Parameters:\n",
    "        current_observation: observations at the current time step\n",
    "        action: actions taken at the current time step\n",
    "        reward: rewards at the current time step\n",
    "        next_observation: observations at the next time step\n",
    "        done: whether the episode has ended or not\n",
    "        model: trainig model\n",
    "        target_model: target model\n",
    "        gamma: discount\n",
    "\n",
    "    Returns:\n",
    "        Computed loss\"\"\"\n",
    "    q_current = model(current_observation)\n",
    "    q_next = target_model(next_observation)\n",
    "\n",
    "    a_next = tf.argmax(model(next_observation), axis=-1)\n",
    "    \n",
    "    q_ref = reward + gamma * tf.reshape(tf.gather(q_next, tf.expand_dims(a_next, axis=-1), batch_dims=1), (-1, )) * (1. - done) # Оценка от таргет модели предсказанных действий основной моделью\n",
    "    \n",
    "    q = tf.reshape(tf.gather(q_current, tf.expand_dims(action, axis=-1), batch_dims=1), (-1, )) # Оценка от основной модели предсказанных действий\n",
    "\n",
    "    return tf.math.reduce_mean(tf.square(q_ref - q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78458a1f-054a-463a-934f-ac3f669c0e27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0aaa7-6ae5-45dc-9c52-04c474ec3ecc",
   "metadata": {},
   "source": [
    "Create models, replay buffers, sampler, optimizer, epsilon decay etc. Implement training loop, show training progress and perform model evaluation once in a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "139138b8-f63c-4a2f-8793-4f96d25a353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmitry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "model = get_model(env.observation_space.shape, 8, 6, 3, name='fuck_UFO', multiply_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ed6857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fuck_UFO\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " fuck_UFO/input (InputLayer)  [(None, 250, 160, 3)]    0         \n",
      "                                                                 \n",
      " fuck_UFO/conv2d_1st_0 (Conv  (None, 250, 160, 8)      224       \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " fuck_UFO/conv2d_2st_0 (Conv  (None, 250, 160, 8)      584       \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " fuck_UFO/PReLU_1st_0 (PReLU  (None, 250, 160, 8)      320000    \n",
      " )                                                               \n",
      "                                                                 \n",
      " fuck_UFO/maxPOOL2d_0 (MaxPo  (None, 125, 80, 8)       0         \n",
      " oling2D)                                                        \n",
      "                                                                 \n",
      " fuck_UFO/dropout_0 (Dropout  (None, 125, 80, 8)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " fuck_UFO/conv2d_1st_1 (Conv  (None, 125, 80, 8)       584       \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " fuck_UFO/conv2d_2st_1 (Conv  (None, 125, 80, 8)       584       \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " fuck_UFO/PReLU_1st_1 (PReLU  (None, 125, 80, 8)       80000     \n",
      " )                                                               \n",
      "                                                                 \n",
      " fuck_UFO/maxPOOL2d_1 (MaxPo  (None, 62, 40, 8)        0         \n",
      " oling2D)                                                        \n",
      "                                                                 \n",
      " fuck_UFO/dropout_1 (Dropout  (None, 62, 40, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " fuck_UFO/conv2d_1st_2 (Conv  (None, 62, 40, 16)       1168      \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " fuck_UFO/conv2d_2st_2 (Conv  (None, 62, 40, 16)       2320      \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " fuck_UFO/PReLU_1st_2 (PReLU  (None, 62, 40, 16)       39680     \n",
      " )                                                               \n",
      "                                                                 \n",
      " fuck_UFO/maxPOOL2d_2 (MaxPo  (None, 31, 20, 16)       0         \n",
      " oling2D)                                                        \n",
      "                                                                 \n",
      " fuck_UFO/dropout_2 (Dropout  (None, 31, 20, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " fuck_UFO/maxPOOL2d_final (M  (None, 15, 10, 16)       0         \n",
      " axPooling2D)                                                    \n",
      "                                                                 \n",
      " fuck_UFO/flattenidze (Flatt  (None, 2400)             0         \n",
      " en)                                                             \n",
      "                                                                 \n",
      " fuck_UFO/prediction (Dense)  (None, 6)                14406     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 459,550\n",
      "Trainable params: 459,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7062a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = get_model(env.observation_space.shape, 8, 6, 3, name='target_fuck_UFO', multiply_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b61bd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model.trainable = False\n",
    "target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cb5084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_buffer = ReplayBuffer(10000, observation_space=env.observation_space, action_space=env.action_space)\n",
    "train_sampler = Sampler(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bc1276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_buffer = ReplayBuffer(100, observation_space=eval_env.observation_space, action_space=eval_env.action_space)\n",
    "eval_sampler = Sampler(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c046ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4, clipnorm=5, decay=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c0fbdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "batch_size = 64\n",
    "decay_epochs = epochs // 2\n",
    "end_epsilon = 0.1\n",
    "update_frequency = 512\n",
    "eval_frequency = 512\n",
    "steps_per_epoch = 32\n",
    "eval_steps = 1000\n",
    "initial_samples = 1000\n",
    "n_evals = 5\n",
    "eval_threshold = 200\n",
    "epsilon_decay = tf.keras.optimizers.schedules.PolynomialDecay(1., decay_epochs, end_learning_rate=end_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0725f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24beced743c47a1ab07f3038ae33193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "total_loss = 0\n",
    "eval_score = 0\n",
    "\n",
    "s, _ = env.reset()\n",
    "pbar = tqdm.trange(epochs)\n",
    "for i in pbar:\n",
    "    train_sampler.epsilon = epsilon_decay(i).numpy()\n",
    "    \n",
    "    s = play_game(model, train_buffer, env, steps_per_epoch, train_sampler, observation=s)\n",
    "    \n",
    "    vals = train_buffer.sample(batch_size)\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as g:\n",
    "        g.watch(model.trainable_weights)\n",
    "        loss = qq_loss(*vals, model, target_model, 0.99)\n",
    "        \n",
    "    gradient = g.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_weights))\n",
    "    \n",
    "    losses.append(loss.numpy())\n",
    "    total_loss += losses[-1]\n",
    "\n",
    "    if (i + 1) % update_frequency == 0:\n",
    "        target_model.set_weights(model.get_weights())\n",
    "\n",
    "    if (i + 1) % eval_frequency == 0:\n",
    "        eval_score = 0\n",
    "\n",
    "        for i in range(n_evals):\n",
    "            eval_buffer.clear()\n",
    "            play_game(model, eval_buffer, eval_env, eval_steps, eval_sampler)\n",
    "            eval_score += eval_buffer.reward[:len(eval_buffer)].sum()\n",
    "\n",
    "        eval_score /= n_evals\n",
    "        if eval_score >= eval_threshold:\n",
    "            break\n",
    "\n",
    "    pbar.set_description(f'L: {losses[-1]:.5f}; AL: {total_loss / (i + 1):.5f}; E: {eval_score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65237283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d8878d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f'./models/atari_model_{eval_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5b44e-55cd-43bb-89dd-87c28cc10a9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e5731-8d24-4482-82ed-7226fb18fa5c",
   "metadata": {},
   "source": [
    "Test the model on the environment and get a cool video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72ec281c-d005-499a-b416-4d0e43437a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gameplay(model: tf.keras.Model, render_mode: str = 'human', n_frames: int = 1000, buffer_capacity: int = 1000):\n",
    "    env = gym.make('ALE/AirRaid-v5', render_mode=render_mode)\n",
    "    buffer = ReplayBuffer(buffer_capacity, env.observation_space, env.action_space)\n",
    "    play_game(model, buffer, env, n_frames, Sampler(0))\n",
    "    # save_video(env.render(), './videos', durations=[1] * len(), fps=24) if you wanna use this line change 'render_mode' -> 'rgb_array_list'\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1da7d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./models/atari_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93564ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = save_gameplay(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7356af55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2075.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.reward.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
