{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9e5ad3-7f90-45f1-ad65-ac8c211b87c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455feed-6c04-4752-8589-6426796bf257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c80e8-a410-4fdd-ba3c-dcc47a7ae912",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79d03c-f1bb-4db5-9094-31b5fec7d2ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac3cf1-8ae5-4de2-a3f9-fb4d9177e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(prefix: str | None = None, suffix: str | None = None, separator: str = '/') -> str | None:\n",
    "    return prefix and prefix + separator + suffix or suffix or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c76ce-9c76-4591-9c2e-dbe75b498201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_bn(\n",
    "    x: tf.Tensor,\n",
    "    channels: int,\n",
    "    kernel_size: int,\n",
    "    padding: str,\n",
    "    strides: int,\n",
    "    activation: str | tf.keras.layers.Activation | None = 'silu',\n",
    "    use_bias: bool = True,\n",
    "    name: str | None = None\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Applies 2D Convolution followed by BatchNormalization and (possibly) `activation`\n",
    "\n",
    "    Arguments:\n",
    "        x: tensor to apply the operation to\n",
    "        channels: number of output channels\n",
    "        kernel_size: kernel size of the convolution\n",
    "        padding: either 'same' or 'valid', padding mode for the convolution\n",
    "        strides: stride size for the convolution\n",
    "        activation: activation to apply after batch normalization\n",
    "        use_bias: whether to learn bias in the convolution\n",
    "        name: name of the operation\n",
    "\n",
    "    Returns:\n",
    "        The resulting tensor\"\"\"\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(channels, kernel_size=kernel_size, padding=padding, use_bias=use_bias, strides=strides, name=get_name(name, 'conv'))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=get_name(name, 'bn'))(x)\n",
    "    \n",
    "    if activation is not None:\n",
    "        x = tf.keras.layers.Activation(activation, name=get_name(name, 'activation'))(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766a3ec-0b5a-4b1e-92dc-fb7cfe554fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottleneck(\n",
    "    x: tf.Tensor,\n",
    "    has_skip_connection: bool,\n",
    "    activation: str | tf.keras.layers.Activation | None = 'silu',\n",
    "    name: str | None = None\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Applies bottleneck block (see YOLOv5 architecture for details)\n",
    "\n",
    "    Arguments:\n",
    "        x: tensor to apply the operation to\n",
    "        has_skip_connection: whether to use skip connection\n",
    "        activation: activation to apply in internal convolutions\n",
    "        name: name of the operation\n",
    "\n",
    "    Returns:\n",
    "        The resulting tensor\"\"\"\n",
    "    \n",
    "    channels = x.shape[-1]\n",
    "    y = get_conv_bn(x, channels, kernel_size=1, padding='valid', strides=1, activation=activation, name=get_name(name, 'conv1'))\n",
    "    y = get_conv_bn(y, channels, kernel_size=3, padding='same',  strides=1, activation=activation, name=get_name(name, 'conv2'))\n",
    "    \n",
    "    if has_skip_connection:\n",
    "        y = tf.keras.layers.Add(name=get_name(name, 'skip_connection'))([y, x])\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d673e-0387-4a94-affd-9a0d17ae470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_C3_block(\n",
    "    x: tf.Tensor,\n",
    "    size: int,\n",
    "    half_size: bool,\n",
    "    activation: str | tf.keras.layers.Activation | None = 'silu',\n",
    "    name: str | None = None\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Applies C3 block (see YOLOv5 architecture for details)\n",
    "\n",
    "    Arguments:\n",
    "        x: tensor to apply the operation to\n",
    "        size: number of bottlenecks\n",
    "        half_size: whether the output channels are half of the input ones\n",
    "        activation: activation to apply in internal convolutions\n",
    "        name: name of the operation\n",
    "\n",
    "    Returns:\n",
    "        The resulting tensor\"\"\"\n",
    "\n",
    "    channels = x.shape[-1] // 2\n",
    "    y = get_conv_bn(x, channels, kernel_size=1, padding='valid', strides=1, activation=activation, name=get_name(name, 'conv1'))\n",
    "    x = get_conv_bn(x, channels, kernel_size=1, padding='valid', strides=1, activation=activation, name=get_name(name, 'conv2'))\n",
    "    \n",
    "    for i in range(size):\n",
    "        x = get_bottleneck(x, half_size, activation=activation, name=get_name(name, f'bottleneck_{i + 1}'))\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(name=get_name(name, 'concatenate'))([x, y])\n",
    "\n",
    "    multiplier = 1\n",
    "    if not half_size:\n",
    "        multiplier = 2\n",
    "\n",
    "    x = get_conv_bn(x, channels * multiplier, kernel_size=1, padding='valid', strides=1, activation=activation, name=get_name(name, 'out_conv')) \n",
    "\n",
    "    return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4f676-0532-4738-b714-2c8bed221f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolo_backbone(\n",
    "    channels: int,\n",
    "    block_sizes: list[int],\n",
    "    pyramid_sizes: list[int],\n",
    "    activation: str | tf.keras.layers.Activation | None = 'silu',\n",
    "    name: str | None = None\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Builds YOLOv5 style model.\n",
    "\n",
    "    Arguments:\n",
    "        channels: number of channels for the first convolution\n",
    "        block_sizes: number of bottleneck layers in each down block\n",
    "        pyramid_sizes: number of bottleneck layers in each pyramid level\n",
    "        activation: activation to apply in internal convolutions\n",
    "        name: name of the model\n",
    "\n",
    "    Return:\n",
    "        The model\"\"\"\n",
    "\n",
    "    inputs = tf.keras.layers.Input((None, None, 3), dtype=tf.uint8, name=get_name(name, 'input'))\n",
    "    x = tf.keras.layers.Rescaling(scale=1. / 127.5, offset=-1, name=get_name(name, 'rescaling'))(inputs)\n",
    "    \n",
    "    x = get_conv_bn(x, channels, kernel_size=6, padding='same', strides=2, activation=activation, name=get_name(name, 'stem'))\n",
    "\n",
    "    levels = []\n",
    "    for i, s in enumerate(block_sizes):\n",
    "        channels *= 2\n",
    "        block_name = get_name(name, f'block_{i + 1}')\n",
    "        \n",
    "        x = get_conv_bn(x, channels, kernel_size=3, padding='same', strides=2, activation=activation, name=get_name(block_name, 'stem'))\n",
    "        x = get_C3_block(x, block_sizes[i], half_size=False, activation=activation, name=get_name(block_name, 'C3'))\n",
    "        levels.append(x)\n",
    "\n",
    "    sppf_name = get_name(name, 'sppf')\n",
    "    x = get_conv_bn(x, channels // 2, kernel_size=1, padding='same', strides=1, activation=activation, name=get_name(sppf_name, 'in_conv'))\n",
    "\n",
    "    max_pools = [x]\n",
    "    for i in range(3):\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=5, strides=1, padding='same', name=get_name(sppf_name, f'max_pool_{i + 1}'))(x)\n",
    "        max_pools.append(x)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(name=get_name(sppf_name, 'concatenate'))(max_pools)\n",
    "    x = get_conv_bn(x, channels, kernel_size=1, padding='valid', strides=1, activation=activation, name=get_name(sppf_name, 'out_conv'))\n",
    "\n",
    "    # пирамидка в обратную сторону\n",
    "\n",
    "    pyramid_levels = [x]\n",
    "    pyramid_name = get_name(name, 'up_pyramid')\n",
    "    \n",
    "    for i, j in enumerate(pyramid_sizes):\n",
    "        block_name = get_name(pyramid_name, f'block_{i + 1}')\n",
    "        \n",
    "        y = levels[-i - 2]\n",
    "        x = pyramid_levels[-1] = get_conv_bn(pyramid_levels[-1], y.shape[-1], kernel_size=1, padding='valid', strides=1, activation=activation, name=get_name(block_name, 'conv'))\n",
    "        \n",
    "        x = tf.keras.layers.UpSampling2D(size=2, interpolation='nearest', name=get_name(block_name, 'upsampling'))(x)\n",
    "        x = tf.keras.layers.Concatenate(name=get_name(block_name, 'concatenate'))([x, y])\n",
    "\n",
    "        x = get_C3_block(x, j, half_size=True, activation=activation, name=get_name(block_name, 'C3'))\n",
    "\n",
    "        pyramid_levels.append(x)\n",
    "\n",
    "    outputs = [pyramid_levels[-1]]\n",
    "    pyramid_name = get_name(name, 'down_pyramid')\n",
    "\n",
    "    for i, j in enumerate(pyramid_sizes[::-1]):\n",
    "        channels = outputs[-1].shape[-1]\n",
    "        block_name = get_name(pyramid_name, f'block_{i + 1}')\n",
    "        \n",
    "        x = get_conv_bn(outputs[-1], channels, kernel_size=3, padding='same', strides=2, activation=activation, name=get_name(block_name, 'conv'))\n",
    "\n",
    "        x = tf.keras.layers.Concatenate(name=get_name(block_name, 'concatenate'))([x, pyramid_levels[-i - 2]])\n",
    "\n",
    "        x = get_C3_block(x, j, half_size=False, activation=activation, name=get_name(block_name, 'C3'))\n",
    "\n",
    "        outputs.append(x)\n",
    "\n",
    "        \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642ee9a-65c2-42dc-a555-21ab8ba56208",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Neck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da293cf0-0229-4f93-b419-289fdc44e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthwise_separable_conv(\n",
    "    x: tf.Tensor,\n",
    "    channels: int,\n",
    "    kernel_size: int,\n",
    "    strides: int,\n",
    "    activation: str | tf.keras.layers.Activation | None = 'silu',\n",
    "    name: str | None = None\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Applies depthwise separable convolution.\n",
    "\n",
    "    Arguments:\n",
    "        x: tensor to apply the operation to\n",
    "        channels: number of output channels\n",
    "        kernel_size: kernel size for the depthwise convolution\n",
    "        strides: stride size for the convolutions\n",
    "        activation: activation to apply in internal convolutions\n",
    "        name: name of the operation\n",
    "\n",
    "    Returns:\n",
    "        The resulting tensor\"\"\"\n",
    "\n",
    "    x = tf.keras.layers.DepthwiseConv2D(kernel_size, use_bias=False, strides=strides, padding='same', name=get_name(name, 'depthwise/conv'))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=get_name(name, 'depthwise/batchnorm'))(x)\n",
    "\n",
    "    if activation is not None:\n",
    "        x = tf.keras.layers.Activation(activation=activation, name=get_name(name, 'depthwise/activation'))(x)\n",
    "\n",
    "    x = get_conv_bn(x, channels, kernel_size=1, use_bias=False, strides=strides, padding='valid', activation=activation, name=get_name(name, 'pointwise'))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f52bfc-8351-4db7-bbf9-427706736d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthwise_separable_convs(\n",
    "    x: tf.Tensor,\n",
    "    channels: int,\n",
    "    out_channels: int,\n",
    "    n_convs: int,\n",
    "    activation: str | tf.keras.layers.Activation | None = 'silu',\n",
    "    name: str | None = None\n",
    "):\n",
    "    \"\"\"Applies depthwise separable convolutions.\n",
    "\n",
    "    Arguments:\n",
    "        x: tensor to apply the operation to\n",
    "        channels: number of output channels\n",
    "        out_channels: number of output channels\n",
    "        n_convs: number of convolutions\n",
    "        activation: activation to apply in internal convolutions\n",
    "        name: name of the operation\n",
    "\n",
    "    Returns:\n",
    "        The resulting tensor\"\"\"\n",
    "    \n",
    "    for i in range(n_convs):\n",
    "        x = depthwise_separable_conv(x, channels, 3, 1, name=get_name(name, f'conv_{i}'), activation=activation)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(out_channels, 3, padding='same', name=get_name(name, 'out_conv'))(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a17c4-22ec-4ec9-abd0-6d5f2433ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFLInitializer(tf.keras.initializers.Initializer):\n",
    "    def __call__(self, shape, dtype=None, **kwargs) -> tf.Tensor:\n",
    "        return tf.reshape(tf.range(shape[2], dtype=dtype), (1, 1, -1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f2805-c98e-4ae2-a0cc-a93e5ff6d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_head(\n",
    "    x: list[tf.Tensor],\n",
    "    n_anchors_per_pixel: int,\n",
    "    n_convs: int,\n",
    "    n_reg: int,\n",
    "    n_classes: int,\n",
    "    activation: str | tf.keras.layers.Activation | None = 'silu',\n",
    "    name: str | None = None,\n",
    ") -> list[tuple[tf.Tensor, tf.Tensor]]:\n",
    "    \"\"\"Applies YOLO detection head.\n",
    "\n",
    "    Arguments:\n",
    "        x: list of outputs from backbone levels\n",
    "        n_anchors_per_pixel: number of anchors per output pixel\n",
    "        n_convs: number of convolutions for each output\n",
    "        n_reg: number of DFL points\n",
    "        n_classes: number of detected classes\n",
    "        activation: activation to apply in internal convolutions\n",
    "        name: name of the operation\n",
    "\n",
    "    Returns:\n",
    "        list of pairs predicted boxes and predicted classes\"\"\"\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for i, y in enumerate(x):\n",
    "        boxes = depthwise_separable_convs(y, max(16, y.shape[-1] // n_reg, n_reg * 4),  n_anchors_per_pixel * n_reg * 4, n_convs, activation, get_name(name, f'prediction_box_{i}'))\n",
    "        boxes = tf.keras.layers.Lambda(lambda x: tf.reshape(x, (tf.shape(x)[0], -1, 4, n_reg)), name=get_name(name, f'reshape_{i}'))(boxes)\n",
    "        boxes = tf.keras.layers.Softmax(name=get_name(name, f'softmax_{i}'))(boxes)\n",
    "\n",
    "        # DFL\n",
    "        boxes = tf.keras.layers.Conv2D(1, 1, kernel_initializer=DFLInitializer(), use_bias=False, padding='valid', name=get_name(name, f'integrate_{i}'), trainable=False)(boxes)\n",
    "        boxes = tf.keras.layers.Lambda(lambda x: tf.reshape(x, (tf.shape(x)[0], -1, 4),), name=get_name(name, f'boxes_{i}/flatten'))(boxes)\n",
    "        \n",
    "        classes = depthwise_separable_convs(y,  max(y.shape[-1], min(n_classes, 128)), n_classes, n_convs, activation, get_name(name, f'prediction_class_{i}'))\n",
    "        classes = tf.keras.layers.Lambda(lambda x: tf.reshape(x, (tf.shape(x)[0], -1, n_classes),), name=get_name(name, f'classes_{i}/flatten'))(classes)\n",
    "\n",
    "        outputs.append((boxes, classes))\n",
    "\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d10160-f23c-46ec-b7bc-73fa31fe84ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88b25fa-a480-4c43-816e-f3830b0674e2",
   "metadata": {},
   "source": [
    "You can use smaller model to make training easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14fefa-afc5-434a-adbd-59aa3cba4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = get_yolo_backbone(64, [3, 6, 9, 3], [3, 3], name='detection_backbone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c1644-b434-4369-ac88-d8502ec51b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = yolo_head(backbone.outputs, n_anchors_per_pixel=2, n_convs=2, n_reg=8, n_classes=1, name='detection_head', activation='silu') # don't forget to change the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195910e3-047e-4681-8e1c-c657046d51f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=backbone.inputs, outputs=predictions, name='detection_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21925d8b-6061-4e7d-9f01-6e663324ca26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a666e69f-c28a-417a-b98f-e7fbf58999fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f488e52-7a8b-4770-87d3-4e2173df8ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(a: tf.Tensor, b: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Computes IOS between boxes\"\"\"\n",
    "\n",
    "    xt = tf.maximum(a[..., 0], b[..., 0])\n",
    "    yt = tf.maximum(a[..., 1], b[..., 1])\n",
    "    xb = tf.minimum(a[..., 2], b[..., 2])\n",
    "    yb = tf.minimum(a[..., 3], b[..., 3])\n",
    "\n",
    "    intersection = tf.maximum(xb - xt, 0) * tf.maximum(yb - yt, 0)\n",
    "    sa = (a[..., 2] - a[..., 0]) * (a[..., 3] - a[..., 1])\n",
    "    sb = (b[..., 2] - b[..., 0]) * (b[..., 3] - b[..., 1])\n",
    "\n",
    "    union = sa + sb - intersection\n",
    "\n",
    "    return intersection / (union + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74185c14-dc3c-489c-a50e-e819ddad9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atss(\n",
    "    boxes: tf.Tensor | np.ndarray,\n",
    "    labels: tf.Tensor | np.ndarray,\n",
    "    anchors: list[tf.Tensor] | list[np.ndarray],\n",
    "    k: int = 9\n",
    ") -> tuple[list[tf.Tensor], list[tf.Tensor]]:\n",
    "    \"\"\"Adaptive Training Sample Selection\n",
    "    \n",
    "    Arguments:\n",
    "        boxes: 2D array of ground-truth boxes specifications (N, 4) in xyxy format\n",
    "        labels: 1D array of box labels (N, )\n",
    "        anchors: list of 2D array anchor specifications (M, 4) in xyxy format  \n",
    "        k: number of closest anchors in each level for ground-truth boxes     \n",
    "    Returns:\n",
    "        labels: list of 1D arrays of labels assigned to each anchor\n",
    "        offsets: list of 2D arrays of offsests assigned to each anchor\n",
    "    \"\"\"\n",
    "    \n",
    "    boxes = tf.cast(boxes, tf.float32)\n",
    "    anchors = [tf.cast(anchor, tf.float32) for anchor in anchors]\n",
    "    \n",
    "    boxes_centers = tf.stack([boxes[:, 2] + boxes[:, 0], boxes[:, 3] + boxes[:, 1]], axis=-1) / 2\n",
    "    anchors_centers = [\n",
    "        tf.stack([anchor[:, 2] + anchor[:, 0], anchor[:, 3] + anchor[:, 1]], axis=-1) / 2 \n",
    "        for anchor in anchors\n",
    "    ]\n",
    "\n",
    "    distances_between_centers = [\n",
    "        tf.norm(tf.expand_dims(boxes_centers, axis=1) - tf.expand_dims(anchor_centers, axis=0), axis=-1) \n",
    "        for anchor_centers in anchors_centers\n",
    "    ]\n",
    "\n",
    "    min_indices = [tf.math.top_k(-i, k=k, sorted=False)[1] for i in distances_between_centers]\n",
    "\n",
    "    selected_anchors = tf.concat([\n",
    "        tf.reshape(tf.gather(anchor, tf.reshape(i, (-1, ))), (-1, k, 4)) \n",
    "        for i, anchor in zip(min_indices, anchors)\n",
    "    ], axis=1)\n",
    "\n",
    "    selected_anchor_centers = tf.concat([\n",
    "        tf.tile(tf.reshape(tf.gather(centers, tf.reshape(i, (-1, ))), (-1, k, 2)), (1, 1, 2))\n",
    "        for i, centers in zip(min_indices, anchors_centers)\n",
    "    ], axis=1)\n",
    "\n",
    "    # not too efficient, but should be easier to understand\n",
    "\n",
    "    expanded_boxes = tf.expand_dims(boxes, axis=1)\n",
    "    l = selected_anchor_centers[..., 0] - expanded_boxes[..., 0]\n",
    "    t = selected_anchor_centers[..., 1] - expanded_boxes[..., 1]\n",
    "    r = expanded_boxes[..., 2] - selected_anchor_centers[..., 2]\n",
    "    b = expanded_boxes[..., 3] - selected_anchor_centers[..., 3]\n",
    "\n",
    "    is_in_box = tf.math.reduce_min(tf.stack([l, t, r, b], axis=-1), axis=-1) > 0\n",
    "    \n",
    "    ious = iou(selected_anchors, tf.expand_dims(boxes, axis=1))\n",
    "    mean = tf.math.reduce_mean(ious, axis=-1)\n",
    "    std  = tf.math.reduce_std(ious, axis=-1)\n",
    "\n",
    "    threshold = mean + std\n",
    "\n",
    "    mask = tf.math.logical_and(ious >= tf.expand_dims(threshold, axis=-1), is_in_box)\n",
    "\n",
    "    labels = tf.tile(tf.expand_dims(labels, axis=-1), (1, len(anchors) * k))\n",
    "\n",
    "    # normalize offsets, so it doesn't depend on the anchor size\n",
    "    \n",
    "    offsets = expanded_boxes - selected_anchor_centers\n",
    "    offsets = offsets / tf.tile(tf.stack([selected_anchors[..., 2] - selected_anchors[..., 0], selected_anchors[..., 3] - selected_anchors[..., 1]], axis=-1), (1, 1, 2))\n",
    "\n",
    "    # flatten everything for easier assignment\n",
    "    \n",
    "    anchors_per_level = [tf.shape(i)[0] for i in anchors]\n",
    "    total_anchros = tf.math.reduce_sum(anchors_per_level)\n",
    "\n",
    "    # adjust indices to index the flattened anchors\n",
    "    min_indices = tf.stack(min_indices, axis=1) + tf.reshape(tf.math.cumsum(anchors_per_level, exclusive=True), (1, -1, 1))\n",
    "\n",
    "    mask = tf.reshape(mask, (-1, ))\n",
    "    labels = tf.reshape(labels, (-1, ))[mask]\n",
    "    offsets = tf.reshape(offsets, (-1, 4))[mask]\n",
    "    min_indices = tf.reshape(min_indices, (-1, 1))[mask]\n",
    "\n",
    "    offsets = tf.split(tf.scatter_nd(min_indices, offsets, (total_anchros, 4)), anchors_per_level)\n",
    "    labels = tf.split(tf.scatter_nd(min_indices, labels, (total_anchros,)), anchors_per_level)\n",
    "\n",
    "    return offsets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6857f121-5bc2-4aba-a235-6260487d41e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_anchors_model(size: int, scales: list[float], stride: int, name: str | None = None) -> tf.keras.Model:\n",
    "    \"\"\"Builds a model to obtain anchor specification for the given output sise\n",
    "\n",
    "    Arguments:\n",
    "        size: anchor size\n",
    "        scales: anchor scales\n",
    "        stride: anchor stride\n",
    "        name: name of the model\n",
    "\n",
    "    Returns:\n",
    "        The model\"\"\"\n",
    "    \n",
    "    inputs = tf.keras.layers.Input((), batch_size=2, name=get_name(name, 'input'))\n",
    "    \n",
    "    shift_x = tf.keras.layers.Lambda(lambda x: tf.range(x[1], dtype=tf.int32) * stride, name=get_name(name, 'center_x'))(inputs)\n",
    "    shift_y = tf.keras.layers.Lambda(lambda x: tf.range(x[0], dtype=tf.int32) * stride, name=get_name(name, 'center_y'))(inputs)\n",
    "    \n",
    "    answ_result = []\n",
    "    for i, scale in enumerate(scales):\n",
    "        anchor = int(-size // 2 * scale)\n",
    "        \n",
    "        coords_x = tf.keras.layers.Lambda(lambda x: x[0] + x[1], name=get_name(name, f'{i}/coords_x'))([shift_x, anchor])\n",
    "        coords_y = tf.keras.layers.Lambda(lambda x: x[0] + x[1], name=get_name(name, f'{i}/coords_y'))([shift_y, anchor])\n",
    "\n",
    "        x, y = tf.keras.layers.Lambda(lambda x: tf.meshgrid(x[0], x[1]), name=get_name(name, f'{i}/meshgrid'))([coords_x, coords_y])\n",
    "\n",
    "        ss = int(size * scale)\n",
    "        result = tf.keras.layers.Lambda(lambda x: tf.stack([x[0], x[1], x[0] + x[2], x[1] + x[2]], axis=-1), name=get_name(name, f'{i}/result'))([x, y, ss])\n",
    "\n",
    "        last_result = tf.keras.layers.Lambda(lambda x: tf.reshape(x, (-1, 4)),name=get_name(name, f'{i}/flatten'))(result)\n",
    "        \n",
    "        answ_result.append(last_result)\n",
    "\n",
    "    outputs = tf.keras.layers.Lambda(lambda x: tf.reshape(tf.concat(x, axis=1), (-1, 4)), name=get_name(name, f'output'))(answ_result)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c54798-371b-4528-b18b-47c3f42b19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_models = [make_anchors_model(i, [1, 2], j) for i, j in zip([16, 64, 256], [8, 16, 32])] # adjust if need be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e28266-ac3b-445c-955a-3ac9a64aa52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [model(np.array(output.shape[1:3])) for model, output in zip(anchors_models, backbone(np.zeros((1, 640, 640, 3))))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d574ff4-c30d-43d0-84c7-6cd5b6cc5057",
   "metadata": {},
   "source": [
    "Build you dataset. Images should be cropped and/or resized to a common size (don't forget to adjust boxes too, can some augmentations be applied?). Keep in mind that ground truth values are corner offsets relative to anchor center w.r.t anchor size and classes for each of the output levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc8612d-ea49-49a3-a1f4-8518301148f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8e607b2-af2f-43a9-b0da-16ae90e62bd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d432b5-265a-4e10-977d-17502666aebb",
   "metadata": {},
   "source": [
    "Implement losses from the paper https://arxiv.org/pdf/2006.04388.pdf . Since tensorflow doesn't allow applying one loss on multiple outputs, implement losses as layers and use model output as loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec4d8bd-3e08-4d9a-a980-3cbb3da1a858",
   "metadata": {},
   "source": [
    "Loss between predicted and true boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb230f9-c3c5-470f-98cc-75388fa7cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIouLoss(tf.keras.losses.Layer):\n",
    "    \n",
    "    def __init__(self, eps: float = 1e-6, name: str | None = None):\n",
    "        super().__init__(name=name)\n",
    "        ...\n",
    "\n",
    "    def call(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        ...\n",
    "        \n",
    "    def get_config(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb0299-99e7-4bc2-8849-21afbe2f4ded",
   "metadata": {},
   "source": [
    "Loss between predicted and true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e1f32-b974-478b-92fe-280ff69bf2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, gamma: float = 2, name: str | None = None):\n",
    "        super().__init__(name=name)\n",
    "        ...\n",
    "        \n",
    "    def call(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        ...\n",
    "    \n",
    "    def get_config(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d632d26d-dcef-4ab7-8a37-d2298973fc58",
   "metadata": {},
   "source": [
    "Loss between predicted distance decomposition and actual (see article for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ced1cc-8245-452b-a670-0695e8a47bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributionFocalLoss(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, name: str | None = None):\n",
    "        super().__init__(name=name)\n",
    "        ...\n",
    "        \n",
    "    def call(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        ...\n",
    "    \n",
    "    def get_config(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4db70-69eb-46e5-a9e2-8c7d0daecf1f",
   "metadata": {},
   "source": [
    "Combined loss. Class loss is applied for every anchor. The rest of the losses are applied for non-background anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611ccf3-557b-468e-8ec6-0d554a768462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionLoss(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        anchors: list[np.ndarray | tf.Tensor],\n",
    "        strides: list[int],\n",
    "        cls_weight: float,\n",
    "        box_weight: float,\n",
    "        dfl_weight: float,\n",
    "        cls_loss: tf.keras.losses.Layer,\n",
    "        box_loss: tf.keras.losses.Layer,\n",
    "        dfl_loss: tf.keras.losses.Layer,\n",
    "        name: str | None = None,\n",
    "):\n",
    "        super().__init__(name=name)\n",
    "        ...\n",
    "        \n",
    "    def get_config(self):\n",
    "        ...\n",
    "          \n",
    "    def call(self, y_true: list[tuple[tf.Tensor, tf.Tensor]], y_pred: list[tuple[tf.Tensor, tf.Tensor]]) -> tf.Tensor:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bddcdb-0197-49d2-ab58-cf4620b3bdfc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257be254-9bb2-4551-bbcc-595fbc8e48b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02b18e4b-404f-4d98-a0fc-2a0f271b57bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e31b9-4995-4c04-a9f1-598c1b34f318",
   "metadata": {},
   "source": [
    "Don't forget to use NMS during prediction [link](https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression_with_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a61fb-f1c4-4426-89de-fb6576a52f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image: np.ndarray, detection_threshold: float, iou_threshold: float) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Predicts boxes for the image.\n",
    "\n",
    "    Returns:\n",
    "        predicted boxes and their respective scores\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da89388-d1d4-4cd7-98e0-a40472cdb13c",
   "metadata": {},
   "source": [
    "Plot some detections on images not present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d5be33-0f70-4dcb-940c-488f0b89214e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
